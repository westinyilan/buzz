"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[836],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>h});var o=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function n(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,o)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?n(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):n(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,o,a=function(e,t){if(null==e)return{};var r,o,a={},n=Object.keys(e);for(o=0;o<n.length;o++)r=n[o],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(o=0;o<n.length;o++)r=n[o],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var l=o.createContext({}),p=function(e){var t=o.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},c=function(e){var t=p(e.components);return o.createElement(l.Provider,{value:t},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},d=o.forwardRef((function(e,t){var r=e.components,a=e.mdxType,n=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=p(r),d=a,h=u["".concat(l,".").concat(d)]||u[d]||m[d]||n;return r?o.createElement(h,i(i({ref:t},c),{},{components:r})):o.createElement(h,i({ref:t},c))}));function h(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var n=r.length,i=new Array(n);i[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:a,i[1]=s;for(var p=2;p<n;p++)i[p]=r[p];return o.createElement.apply(null,i)}return o.createElement.apply(null,r)}d.displayName="MDXCreateElement"},3584:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>m,frontMatter:()=>n,metadata:()=>s,toc:()=>p});var o=r(7462),a=(r(7294),r(3905));const n={title:"FAQ",sidebar_position:5},i=void 0,s={unversionedId:"faq",id:"faq",title:"FAQ",description:"1. Where are the models stored?",source:"@site/docs/faq.md",sourceDirName:".",slug:"/faq",permalink:"/buzz/docs/faq",draft:!1,tags:[],version:"current",sidebarPosition:5,frontMatter:{title:"FAQ",sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"CLI",permalink:"/buzz/docs/cli"}},l={},p=[],c={toc:p},u="wrapper";function m(e){let{components:t,...r}=e;return(0,a.kt)(u,(0,o.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Where are the models stored?")),(0,a.kt)("p",{parentName:"li"},"The models are stored in ",(0,a.kt)("inlineCode",{parentName:"p"},"~/.cache/Buzz")," (Linux), ",(0,a.kt)("inlineCode",{parentName:"p"},"~/Library/Caches/Buzz"),"\n(Mac OS) or ",(0,a.kt)("inlineCode",{parentName:"p"},"%USERPROFILE%\\AppData\\Local\\Buzz\\Buzz\\Cache")," (Windows)."),(0,a.kt)("p",{parentName:"li"},"Paste the location in your file manager to access the models.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"What can I try if the transcription runs too slowly?")),(0,a.kt)("p",{parentName:"li"},"Speech recognition requires large amount of computation, so one option is to try using a lower Whisper model size or using a Whisper.cpp model to run speech recognition of your computer. If you have access to a computer with GPU that has at least 6GB of VRAM you can try using the Faster Whisper model."),(0,a.kt)("p",{parentName:"li"},"Buzz also supports using OpenAI API to do speech recognition on a remote server. To use this feature you need to set OpenAI API key in Preferences. See ",(0,a.kt)("a",{parentName:"p",href:"https://chidiwilliams.github.io/buzz/docs/preferences"},"Preferences")," section for more details.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"How to record system audio?")),(0,a.kt)("p",{parentName:"li"},"To transcribe system audio you need to configure virtual audio device and connect output from the applications you want to transcribe to this virtual speaker. After that you can select it as source in the Buzz. See ",(0,a.kt)("a",{parentName:"p",href:"https://chidiwilliams.github.io/buzz/docs/usage/live_recording"},"Usage")," section for more details."),(0,a.kt)("p",{parentName:"li"},"Relevant tools:"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Mac OS - ",(0,a.kt)("a",{parentName:"li",href:"https://github.com/ExistentialAudio/BlackHole"},"BlackHole"),"."),(0,a.kt)("li",{parentName:"ul"},"Windows - ",(0,a.kt)("a",{parentName:"li",href:"https://vb-audio.com/Cable/"},"VB CABLE")),(0,a.kt)("li",{parentName:"ul"},"Linux - ",(0,a.kt)("a",{parentName:"li",href:"https://wiki.ubuntu.com/record_system_sound"},"PulseAudio Volume Control")))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"What model should I use?")),(0,a.kt)("p",{parentName:"li"},"Model size to use will depend on your hardware and use case. Smaller models will work faster but will have more inaccuracies. Larger models will be more accurate but will require more powerful hardware or longer time to transcribe. "),(0,a.kt)("p",{parentName:"li"},'When choosing among large models consider the following. "Large" is the first released older model, "Large-V2" is later updated model with better accuracy, for some languages considered the most robust and stable. "Large-V3" is the latest model with the best accuracy in many cases, but some times can hallucinate or invent words that were never in the audio. "Turbo" model tries to get a good balance between speed and accuracy. The only sure way to know what model best suits your needs is to test them all in your language. ')),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"How to get GPU acceleration for faster transcription?")),(0,a.kt)("p",{parentName:"li"},"On Linux GPU acceleration is supported out of the box on Nvidia GPUs. If you still get any issues install ",(0,a.kt)("a",{parentName:"p",href:"https://developer.nvidia.com/cuda-downloads"},"CUDA 12"),", ",(0,a.kt)("a",{parentName:"p",href:"https://developer.nvidia.com/cublas"},"cuBLASS")," and ",(0,a.kt)("a",{parentName:"p",href:"https://developer.nvidia.com/cudnn"},"cuDNN"),"."),(0,a.kt)("p",{parentName:"li"},"On Windows see ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/chidiwilliams/buzz/blob/main/CONTRIBUTING.md#gpu-support"},"this note")," on enabling CUDA GPU support."),(0,a.kt)("p",{parentName:"li"},"For Faster whisper CUDA 12 is required, computers with older CUDA versions will use CPU.   ")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"How to fix ",(0,a.kt)("inlineCode",{parentName:"strong"},"Unanticipated host error[PaErrorCode-9999]"),"?")),(0,a.kt)("p",{parentName:"li"},"Check if there are any system settings preventing apps from accessing the microphone."),(0,a.kt)("p",{parentName:"li"},"On Windows, see if Buzz has permission to use the microphone in Settings -> Privacy -> Microphone."),(0,a.kt)("p",{parentName:"li"},"See method 1 in this video ",(0,a.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=eRcCYgOuSYQ"},"https://www.youtube.com/watch?v=eRcCYgOuSYQ")),(0,a.kt)("p",{parentName:"li"},"For method 2 there is no need to uninstall the antivirus, but see if you can temporarily disable it or if there are settings that may prevent Buzz from accessing the microphone.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Can I use Buzz on a computer without internet?")),(0,a.kt)("p",{parentName:"li"},'Yes, Buzz can be used without internet connection if you download the necessary models on some other computer that has the internet and manually move them to the offline computer. The easiest way to find where the models are stored is to go to Help -> Preferences -> Models. Then download some model, and push "Show file location" button. This will open the folder where the models are stored. Copy the models folder to the same location on the offline computer. F.e. for Linux it is ',(0,a.kt)("inlineCode",{parentName:"p"},".cache/Buzz/models")," in your home directory.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Buzz crashes, what to do?")),(0,a.kt)("p",{parentName:"li"},"If a model download was incomplete or corrupted, Buzz may crash. Try to delete the downloaded model files in ",(0,a.kt)("inlineCode",{parentName:"p"},"Help -> Preferences -> Models")," and re-download them."),(0,a.kt)("p",{parentName:"li"},"If that does not help, check the log file for errors and ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/chidiwilliams/buzz/issues"},"report the issue")," so we can fix it. The log file is located in ",(0,a.kt)("inlineCode",{parentName:"p"},"~/Library/Logs/Buzz")," (Mac OS) or ",(0,a.kt)("inlineCode",{parentName:"p"},"%USERPROFILE%\\AppData\\Local\\Buzz\\Buzz\\Logs")," (Windows). On Linux run the Buzz from the command line to see the relevant messages."))))}m.isMDXComponent=!0}}]);